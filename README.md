# Bias Detection Project

This project aims to analyze and detect potential biases in credit scoring systems using a custom dataset and an implementation in C++ for the backend, alongside other tools for visualization and analysis. This project primarily focuses on African communities and people of African descent.

---

## **Purpose**

The project is designed to:
1. Evaluate fairness in credit scoring systems by analyzing demographic data.
2. Detect biases such as:
   - Disparate Impact.
   - False Positive Rates across groups.
   - Demographic Parity.
3. Provide a modular structure for integrating custom datasets and extending functionality.

---

## **Example Execution**

After running the program, the output will include metrics such as:
- False Positive Rate for each demographic group.
- Average credit scores by race, gender, and region.
- Overall bias evaluation, including a letter grade.

Example output:

```
False Positive Rate (Black): 0.333
Group Disparity (Black vs White): 0.87
Letter Grade: B
```

---

## **Acknowledgments**

This project is for educational and testing purposes only. All datasets are synthetic and do not represent real-world individuals.

---

## **License**
This project is distributed under the MIT License. You are free to use, modify, and distribute it for educational and non-commercial purposes.

